{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation_id', 'email', 'maximum_brevity_summary', 'summary', 'distilabel_metadata', 'model_name'],\n",
       "        num_rows: 363584\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=load_dataset('argilla/FinePersonas-Conversations-Email-Summaries')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversation_id', 'email', 'maximum_brevity_summary', 'summary', 'distilabel_metadata', 'model_name'],\n",
       "    num_rows: 165000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small=data['train'].select(range(165000))\n",
    "data_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation_id', 'email', 'maximum_brevity_summary', 'summary', 'distilabel_metadata', 'model_name'],\n",
       "        num_rows: 148500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['conversation_id', 'email', 'maximum_brevity_summary', 'summary', 'distilabel_metadata', 'model_name'],\n",
       "        num_rows: 16500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small=data_small.train_test_split(test_size=0.1)\n",
    "data_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_id': 996,\n",
       " 'email': \"Subject: Re: Reaching out for expertise\\n\\nEmily,\\n\\nI had a chance to review the outline, and I think it's a great starting point. I made a few suggestions and added some terms I think would be valuable to include. Please see the attached revised outline.\\n\\nI've also been thinking about how we could expand our collaboration beyond the glossary. I believe there's an opportunity to create an online course that combines your expertise in science communication and my knowledge of fertility education. We could use the glossary as the foundation and build upon it with engaging content, visuals, and interactive elements.\\n\\nWhat do you think? I'm happy to discuss this idea further during our call on Tuesday.\\n\\nBest regards,\\nOlivia\",\n",
       " 'maximum_brevity_summary': 'Olivia reviewed and revised the outline, suggesting an expansion into an online course.',\n",
       " 'summary': 'Olivia reviewed the outline and made suggestions, adding valuable terms. She proposes expanding the collaboration to create an online course that combines expertise in science communication and fertility education, using the glossary as a foundation. Olivia suggests discussing this further during the call on Tuesday.',\n",
       " 'distilabel_metadata': {'raw_input_email_summarization_0': [{'content': 'You are an AI assistant designed to summarize emails for the recipient of the email. Your task is to create concise, objective summaries that capture the essential information communicated by the sender, from the recipient\\'s perspective but without directly addressing or mentioning the recipient.\\n\\n## Key points\\n\\n1. Do not use phrases like \"you\" or \"the recipient\" in the summary.\\n2. Do not use the recipient name.\\n3. Do not use the third person.\\n4. Focus on the sender\\'s actions and intentions.\\n5. Summarize as if describing the email to a third party.\\n\\nFor example, instead of \"Alex is reaching out to you to collaborate\" or \"Alex is reaching out Samantha to collaborate\", use \"Alex is reaching out to collaborate\".\\n\\n## Output Requirements\\n\\nProvide two types of summaries:\\n1. A maximum brevity summary: extract the main key point of the conversation and present it in one very very short sentence. Include details such as dates, cities, venues, etc if required.\\n2. A more detailed summary (up to three sentences).\\n\\n## Output Format:\\n\\n```markdown\\n## Maximum brevity summary\\n\\n[One-sentence summary here]\\n\\n## Summary\\n\\n[Up to three-sentence summary here]\\n```\\n',\n",
       "    'role': 'system'},\n",
       "   {'content': \"Subject: Re: Reaching out for expertise\\n\\nEmily,\\n\\nI had a chance to review the outline, and I think it's a great starting point. I made a few suggestions and added some terms I think would be valuable to include. Please see the attached revised outline.\\n\\nI've also been thinking about how we could expand our collaboration beyond the glossary. I believe there's an opportunity to create an online course that combines your expertise in science communication and my knowledge of fertility education. We could use the glossary as the foundation and build upon it with engaging content, visuals, and interactive elements.\\n\\nWhat do you think? I'm happy to discuss this idea further during our call on Tuesday.\\n\\nBest regards,\\nOlivia\",\n",
       "    'role': 'user'}],\n",
       "  'raw_output_email_summarization_0': '## Maximum brevity summary\\n\\nOlivia reviewed and revised the outline, suggesting an expansion into an online course.\\n\\n## Summary\\n\\nOlivia reviewed the outline and made suggestions, adding valuable terms. She proposes expanding the collaboration to create an online course that combines expertise in science communication and fertility education, using the glossary as a foundation. Olivia suggests discussing this further during the call on Tuesday.'},\n",
       " 'model_name': 'Qwen/Qwen2.5-72B-Instruct'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Olivia reviewed and revised the outline, suggesting an expansion into an online course.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small['train'][0]['maximum_brevity_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Olivia reviewed the outline and made suggestions, adding valuable terms. She proposes expanding the collaboration to create an online course that combines expertise in science communication and fertility education, using the glossary as a foundation. Olivia suggests discussing this further during the call on Tuesday.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small['train'][0]['summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c13e2e12aff499ab3c46c5758ae7d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ba8ab4d6324834a6ac3ed3256115a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d164e207f9a4d74b4fd5b0d1db58652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6425b2450245e59a8a8f8ef6dc326b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_point='facebook/bart-base' #facebook/bart-large-cnn\n",
    "tokenizer=AutoTokenizer.from_pretrained(check_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input=data_small.remove_columns([\n",
    "    'conversation_id', 'summary','distilabel_metadata', 'model_name'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['email', 'maximum_brevity_summary'],\n",
       "        num_rows: 148500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['email', 'maximum_brevity_summary'],\n",
       "        num_rows: 16500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=1024\n",
    "max_target=128\n",
    "def token_func(example):\n",
    "    input=tokenizer(\n",
    "        example['email'],\n",
    "        max_length=max_length,\n",
    "        truncation=True\n",
    "        )\n",
    "    labels=tokenizer(\n",
    "        example['maximum_brevity_summary'],\n",
    "        max_length=max_target,\n",
    "        truncation=True\n",
    "        )\n",
    "    input['labels']=labels['input_ids']\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd9e4f43d494a01a999c5cbbeab5bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/148500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97c0eb68fe74cd794a170d58570660d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_ecd=data_input.map(token_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['email', 'maximum_brevity_summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 148500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['email', 'maximum_brevity_summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 16500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 148500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 16500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ecd=data_ecd.remove_columns(['email','maximum_brevity_summary'])\n",
    "data_ecd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peft model\n",
    "* Using LORA to fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d03a1b5658e495f978219614003c9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loading model\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(check_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartForConditionalGeneration(\n",
      "  (model): BartModel(\n",
      "    (shared): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
      "    (encoder): BartEncoder(\n",
      "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
      "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x BartEncoderLayer(\n",
      "          (self_attn): BartSdpaAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): GELUActivation()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): BartDecoder(\n",
      "      (embed_tokens): BartScaledWordEmbedding(50265, 768, padding_idx=1)\n",
      "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x BartDecoderLayer(\n",
      "          (self_attn): BartSdpaAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (activation_fn): GELUActivation()\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BartSdpaAttention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config=LoraConfig(\n",
    "    r=8,\n",
    "    task_type='SEQ_2_SEQ_LM',\n",
    "    target_modules=['k_proj', 'v_proj', 'q_proj', 'out_proj']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 140,305,152 || trainable%: 0.6306\n"
     ]
    }
   ],
   "source": [
    "model_peft=get_peft_model(model, model_config).to(device)\n",
    "model_peft.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator=DataCollatorForSeq2Seq(\n",
    "    tokenizer, \n",
    "    model,\n",
    "    #model_peft\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch=10\n",
    "batch_size=4\n",
    "training_args=Seq2SeqTrainingArguments(\n",
    "    output_dir='Summarization',\n",
    "    num_train_epochs=n_epoch,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    eval_strategy='epoch',\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch'   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_149804/1622741389.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer=Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer=Seq2SeqTrainer(\n",
    "    model,\n",
    "    #model_peft,\n",
    "    training_args,\n",
    "    train_dataset=data_ecd['train'],\n",
    "    eval_dataset=data_ecd['test'],\n",
    "    data_collator=data_collator,\n",
    "    #compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bf2d2a36444044ab0cbf5630346c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/371260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1177, 'grad_norm': 3.1435399055480957, 'learning_rate': 4.75e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6225cc8e2220476bb7ea5ef408b3625f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8072907328605652, 'eval_runtime': 120.1154, 'eval_samples_per_second': 137.368, 'eval_steps_per_second': 17.175, 'epoch': 1.0}\n",
      "{'loss': 0.9268, 'grad_norm': 3.656320095062256, 'learning_rate': 4.5e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9350cb28f38742f782a15761e8594efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7364647388458252, 'eval_runtime': 120.0431, 'eval_samples_per_second': 137.451, 'eval_steps_per_second': 17.185, 'epoch': 2.0}\n",
      "{'loss': 0.8657, 'grad_norm': 2.831218957901001, 'learning_rate': 4.25e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c82059514a403891098567fc92b677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7016783356666565, 'eval_runtime': 119.9694, 'eval_samples_per_second': 137.535, 'eval_steps_per_second': 17.196, 'epoch': 3.0}\n",
      "{'loss': 0.8277, 'grad_norm': 2.8726093769073486, 'learning_rate': 4e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1508068ddf55459cb853108d015a93d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6784924864768982, 'eval_runtime': 119.8769, 'eval_samples_per_second': 137.641, 'eval_steps_per_second': 17.209, 'epoch': 4.0}\n",
      "{'loss': 0.8012, 'grad_norm': 3.9873626232147217, 'learning_rate': 3.7500000000000003e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c51e2556b314a098dee30ec31e802eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6583265066146851, 'eval_runtime': 119.7314, 'eval_samples_per_second': 137.808, 'eval_steps_per_second': 17.23, 'epoch': 5.0}\n",
      "{'loss': 0.7807, 'grad_norm': 2.719867467880249, 'learning_rate': 3.5e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfc419eae6743eab1936cb8e7517ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6415004134178162, 'eval_runtime': 119.7494, 'eval_samples_per_second': 137.788, 'eval_steps_per_second': 17.228, 'epoch': 6.0}\n",
      "{'loss': 0.765, 'grad_norm': 2.8422605991363525, 'learning_rate': 3.2500000000000004e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dff957cbba14ca7a6168f1571c0bdb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6389526724815369, 'eval_runtime': 119.7124, 'eval_samples_per_second': 137.83, 'eval_steps_per_second': 17.233, 'epoch': 7.0}\n",
      "{'loss': 0.7517, 'grad_norm': 3.8478503227233887, 'learning_rate': 3e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc341ee507b4efb8932de21b4366eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6312384009361267, 'eval_runtime': 119.6692, 'eval_samples_per_second': 137.88, 'eval_steps_per_second': 17.239, 'epoch': 8.0}\n",
      "{'loss': 0.741, 'grad_norm': 3.2151739597320557, 'learning_rate': 2.7500000000000004e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5fa09462374ac990f9154a8a4ded2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6209737062454224, 'eval_runtime': 119.6625, 'eval_samples_per_second': 137.888, 'eval_steps_per_second': 17.24, 'epoch': 9.0}\n",
      "{'loss': 0.7323, 'grad_norm': 2.5233752727508545, 'learning_rate': 2.5e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c29348657f54b48beeeea7209fa0088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6165818572044373, 'eval_runtime': 119.6475, 'eval_samples_per_second': 137.905, 'eval_steps_per_second': 17.242, 'epoch': 10.0}\n",
      "{'loss': 0.7251, 'grad_norm': 2.726480722427368, 'learning_rate': 2.25e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cffadadd7c41989b0b44689164b63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.610162615776062, 'eval_runtime': 119.6747, 'eval_samples_per_second': 137.874, 'eval_steps_per_second': 17.238, 'epoch': 11.0}\n",
      "{'loss': 0.7181, 'grad_norm': 2.872225284576416, 'learning_rate': 2e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a394e018754e979511880036dd2a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6049325466156006, 'eval_runtime': 119.6334, 'eval_samples_per_second': 137.921, 'eval_steps_per_second': 17.244, 'epoch': 12.0}\n",
      "{'loss': 0.7122, 'grad_norm': 2.6132428646087646, 'learning_rate': 1.75e-05, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e2cf4286ad421e9d0e7e09084458f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6025649905204773, 'eval_runtime': 119.6363, 'eval_samples_per_second': 137.918, 'eval_steps_per_second': 17.244, 'epoch': 13.0}\n",
      "{'loss': 0.7078, 'grad_norm': 2.4376466274261475, 'learning_rate': 1.5e-05, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65cf17d806b462d8c1c5f8ba6377dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6003775596618652, 'eval_runtime': 119.5791, 'eval_samples_per_second': 137.984, 'eval_steps_per_second': 17.252, 'epoch': 14.0}\n",
      "{'loss': 0.7042, 'grad_norm': 2.9944655895233154, 'learning_rate': 1.25e-05, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d2ea53f6e24681ad904a726e0cdd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5969794988632202, 'eval_runtime': 119.5729, 'eval_samples_per_second': 137.991, 'eval_steps_per_second': 17.253, 'epoch': 15.0}\n",
      "{'loss': 0.7014, 'grad_norm': 3.6201438903808594, 'learning_rate': 1e-05, 'epoch': 16.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6b36f59282471f904cf111ad9085a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5952738523483276, 'eval_runtime': 119.6041, 'eval_samples_per_second': 137.955, 'eval_steps_per_second': 17.249, 'epoch': 16.0}\n",
      "{'loss': 0.698, 'grad_norm': 3.2962067127227783, 'learning_rate': 7.5e-06, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc2b7f9ea1b4c6cb6b39fcf2a6a1551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5933892130851746, 'eval_runtime': 119.5714, 'eval_samples_per_second': 137.993, 'eval_steps_per_second': 17.253, 'epoch': 17.0}\n",
      "{'loss': 0.6958, 'grad_norm': 2.539396047592163, 'learning_rate': 5e-06, 'epoch': 18.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fe18743cc64f8cb1ceea76e4c2b771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5928394198417664, 'eval_runtime': 119.6053, 'eval_samples_per_second': 137.954, 'eval_steps_per_second': 17.248, 'epoch': 18.0}\n",
      "{'loss': 0.6931, 'grad_norm': 3.201368570327759, 'learning_rate': 2.5e-06, 'epoch': 19.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20869e06e304fb894f56ee2e241cada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5914831757545471, 'eval_runtime': 119.5628, 'eval_samples_per_second': 138.003, 'eval_steps_per_second': 17.255, 'epoch': 19.0}\n",
      "{'loss': 0.6927, 'grad_norm': 3.764519214630127, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da394d63d7b47c6ada843051e01d0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.591890811920166, 'eval_runtime': 119.4881, 'eval_samples_per_second': 138.089, 'eval_steps_per_second': 17.265, 'epoch': 20.0}\n",
      "{'train_runtime': 54579.3888, 'train_samples_per_second': 54.416, 'train_steps_per_second': 6.802, 'train_loss': 0.7679103551082799, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=371260, training_loss=0.7679103551082799, metrics={'train_runtime': 54579.3888, 'train_samples_per_second': 54.416, 'train_steps_per_second': 6.802, 'total_flos': 4.626931935228641e+17, 'train_loss': 0.7679103551082799, 'epoch': 20.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model.save_pretrained('./summarization_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=pipeline(\n",
    "    'summarization',\n",
    "    model='summarization_peft',\n",
    "    #\"facebook/bart-large-cnn\",\n",
    "    #check_point,\n",
    "    #\n",
    "    #max_length=1028,\n",
    "    device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
