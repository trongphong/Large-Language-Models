{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator=Accelerator()\n",
    "device=accelerator.device\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point='Helsinki-NLP/opus-mt-en-fr'\n",
    "data=load_dataset('kde4', lang1='en', lang2='fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 189155\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 21018\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data['train'].train_test_split(test_size=0.1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'How can i send good debug or crash reports?',\n",
       " 'fr': 'Comment puis -je envoyer de bons rapports de d√©bogue ou de plantage & #160;?'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][1]['translation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phong/miniconda3/envs/mlenv/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(check_point, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "max_length=128\n",
    "def token_func(text):\n",
    "    en_text=[sentence['en'] for sentence in text['translation']]\n",
    "    fr_text=[sentence['fr'] for sentence in text['translation']]\n",
    "    text_token=tokenizer(\n",
    "        en_text, \n",
    "        text_target=fr_text,\n",
    "        max_length=128,\n",
    "        truncation=True\n",
    "        )\n",
    "    return text_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b63568e634448be9348e3c3822ecb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/189155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53411f3af6264f2ab99367c60b7d09ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21018 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_ecd=data.map(token_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 189155\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21018\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input=data_ecd.remove_columns(['translation', 'id'])\n",
    "#data_input=data_input.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 189155\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 21018\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading model\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(check_point).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarianMTModel(\n",
      "  (model): MarianModel(\n",
      "    (shared): Embedding(59514, 512, padding_idx=59513)\n",
      "    (encoder): MarianEncoder(\n",
      "      (embed_tokens): Embedding(59514, 512, padding_idx=59513)\n",
      "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x MarianEncoderLayer(\n",
      "          (self_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): SiLU()\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): MarianDecoder(\n",
      "      (embed_tokens): Embedding(59514, 512, padding_idx=59513)\n",
      "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x MarianDecoderLayer(\n",
      "          (self_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (activation_fn): SiLU()\n",
      "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=59514, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Lora to fine-tune model\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration \n",
    "peft_config=LoraConfig(\n",
    "    r=8,\n",
    "    task_type='SEQ_2_SEQ_LM',\n",
    "    inference_mode=False,    \n",
    "    target_modules=['k_proj', 'v_proj', 'q_proj', 'out_proj']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 589,824 || all params: 75,723,776 || trainable%: 0.7789\n"
     ]
    }
   ],
   "source": [
    "peft_model=get_peft_model(model, peft_config).to(device)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data collator\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collator=DataCollatorForSeq2Seq(tokenizer, peft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric=evaluate.load('sacrebleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predict):\n",
    "    preds, labels=predict\n",
    "    preds_dcd=tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels=np.where(labels !=-100, labels, tokenizer.pad_token_id)\n",
    "    labels_dcd=tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    print(len(labels_dcd))\n",
    "    print(len(preds_dcd))\n",
    "    preds_dcd=[w.strip() for w in preds_dcd]\n",
    "    labels_dcd=[[w.strip()] for w in labels_dcd]\n",
    "    print(len(labels_dcd))\n",
    "    print(len(preds_dcd))\n",
    "    result=metric.compute(predictions=preds_dcd, references=labels_dcd)\n",
    "    return{'Blue score': result['score']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "train_args=Seq2SeqTrainingArguments(\n",
    "    output_dir='translate_Helsiki',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    eval_strategy='epoch',\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch'   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15984/2190063032.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer=Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer=Seq2SeqTrainer(\n",
    "    peft_model,\n",
    "    train_args,\n",
    "    train_dataset=data_input['train'],\n",
    "    eval_dataset=data_input['test'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_model, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac892c3a8df4541bae6705379d88af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70935 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4861, 'grad_norm': 1.5121797323226929, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9872910585044f9eae367175bcc451ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2718814611434937, 'eval_runtime': 39.6491, 'eval_samples_per_second': 530.1, 'eval_steps_per_second': 66.281, 'epoch': 1.0}\n",
      "{'loss': 1.3741, 'grad_norm': 3.527168035507202, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7ffe4f492544e2ac80e4afd88f852c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.229673147201538, 'eval_runtime': 39.1097, 'eval_samples_per_second': 537.411, 'eval_steps_per_second': 67.196, 'epoch': 2.0}\n",
      "{'loss': 1.3427, 'grad_norm': 3.540693998336792, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337e166473a14a6c8e9e5ed4649346d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2161872386932373, 'eval_runtime': 39.7111, 'eval_samples_per_second': 529.273, 'eval_steps_per_second': 66.178, 'epoch': 3.0}\n",
      "{'train_runtime': 2855.7013, 'train_samples_per_second': 198.713, 'train_steps_per_second': 24.84, 'train_loss': 1.4009786137837457, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=70935, training_loss=1.4009786137837457, metrics={'train_runtime': 2855.7013, 'train_samples_per_second': 198.713, 'train_steps_per_second': 24.84, 'total_flos': 6124534889840640.0, 'train_loss': 1.4009786137837457, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained('./translation_peft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phong/miniconda3/envs/mlenv/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "pipe=pipeline('translation', model='translation_peft', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'nous regardons un film'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('we watching a film')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
